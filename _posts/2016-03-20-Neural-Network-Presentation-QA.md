---
layout: post
title:  "Neural Network Presentation QA"
date:   2016-03-20
categories: QDL 
---

1. Why we need Neural Networks?<br />
**Answer**: when feature is too many, the complexity is too high.

2. What is logistic unit in Neural Networks?<br/>
**Answer:** input layer x -\> hidden layer a(j,i) -\> output layer h(x)

3. What does a(j,i) mean in Neural Networks?<br/>
**Answer:** It is the activation of unit i in layer j. or a<sup>j</sup><sub>i</sub> 

4. What is Foward Propagation?<br/>
**Answer:** input -\> activation -\> output h(x). 
